# Criteo Kaggle Configurations
# --arch-sparse-feature-size=16
# --arch-embedding-size='3-4-10-15-18-24-27-105-305-583-633-1460-2173-3194-5652-5683-12517-14992-93145-142572-286181-2202608-5461306-7046547-8351593-10131227'
# --arch-mlp-bot='13-512-256-64-16'
# --arch-mlp-top='512-256-1'

# Criteo Terabyte Configurations
# --arch-sparse-feature-size=64
# --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222'
# --arch-mlp-bot='13-512-256-64'
# --arch-mlp-top='512-512-256-1'

# DHE Configuration Ranges
# --dhe-k={2, 2048} # larger k = more encoder hash functions.
# --dhe-mlp-dims={k-16, k-512-256-16} # larger mlp-dims = larger decoder mlp stacks.

# Example Run Commands (using Kaggle configuration that is built into parser as defaults)
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'dhe' --print-time
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'dhe' --use-gpu --print-time
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'hybrid' --print-time
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'hybrid' --use-gpu --print-time
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'select' --print-time
python dlrm_s_pytorch.py --num-batches=100 --mini-batch-size=16 --embedding-representation 'select' --use-gpu --print-time

# Example Run Commands (using Terabyte configuration)
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'dhe' --print-time
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'dhe' --use-gpu --print-time
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'hybrid' --print-time
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'hybrid' --use-gpu --print-time
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'select' --print-time
python dlrm_s_pytorch.py --arch-sparse-feature-size=64 --arch-embedding-size='3-4-10-14-36-61-101-122-970-1442-2208-7112-7378-11156-12420-17217-20134-36084-313829-415421-1333352-7267859-9758201-9946608-9980333-9994222' --arch-mlp-bot='13-512-256-64' --arch-mlp-top='512-512-256-1' --num-batches=100 --mini-batch-size=16 --embedding-representation 'select' --use-gpu --print-time